<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MyText</title>
    <script src="https://aka.ms/csspeech/jsbrowserpackageraw"></script>
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">
    <style>
        :root {
            --primary: #4f46e5;
            --primary-hover: #4338ca;
            --background: #f9fafb;
            --card: #ffffff;
            --text: #1f2937;
            --border: #e5e7eb;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, sans-serif;
        }

        body {
            background-color: var(--background);
            color: var(--text);
            line-height: 1.5;
            padding: 0rem;
        }

        .container {
            max-width: 1000px;
            margin: 0 auto;
        }

        .card {
            background: var(--card);
            border-radius: 1rem;
            box-shadow: 0 4px 6px -1px rgb(0 0 0 / 0.1);
            padding: 2rem;
            margin-bottom: 1.5rem;
        }

        h1 {
            font-size: 1.875rem;
            font-weight: 700;
            margin-bottom: 2rem;
            text-align: center;
            color: var(--primary);
        }

        .config-form {
            display: grid;
            gap: 1rem;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            margin-bottom: 1.5rem;
        }

        .input-group {
            display: flex;
            flex-direction: column;
            gap: 0.5rem;
        }

        .input-group label {
            font-weight: 500;
            font-size: 0.875rem;
        }

        input, select {
            padding: 0.75rem;
            border: 1px solid var(--border);
            border-radius: 0.5rem;
            font-size: 1rem;
            transition: border-color 0.2s;
        }

        input:focus, select:focus {
            outline: none;
            border-color: var(--primary);
            ring: 2px solid var(--primary);
        }

        .upload-zone {
            border: 2px dashed var(--border);
            border-radius: 1rem;
            padding: 2rem;
            text-align: center;
            transition: all 0.3s;
            cursor: pointer;
        }

        .upload-zone.drag-over {
            border-color: var(--primary);
            background-color: #f5f7ff;
        }

        .button {
            background-color: var(--primary);
            color: white;
            padding: 0.75rem 1.5rem;
            border: none;
            border-radius: 0.5rem;
            font-weight: 500;
            cursor: pointer;
            transition: background-color 0.2s;
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
        }

        .button:hover {
            background-color: var(--primary-hover);
        }

        .button:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }

        .button-secondary {
            background-color: white;
            border: 1px solid var(--border);
            color: var(--text);
        }

        .button-secondary:hover {
            background-color: var(--background);
        }

        .actions {
            display: flex;
            gap: 1rem;
            justify-content: center;
            margin: 1.5rem 0;
        }

        .output-container {
            position: relative;
        }

        .output {
            min-height: 200px;
            max-height: 400px;
            overflow-y: auto;
            padding: 1rem;
            border: 1px solid var(--border);
            border-radius: 0.5rem;
            background-color: white;
            font-size: 0.95rem;
            line-height: 1.6;
        }

        .copy-button {
            position: absolute;
            top: 0.5rem;
            right: 0.5rem;
            padding: 0.5rem;
            background: white;
            border: 1px solid var(--border);
            border-radius: 0.375rem;
            cursor: pointer;
            transition: all 0.2s;
        }

        .copy-button:hover {
            background: var(--background);
        }

        .progress-bar {
            height: 4px;
            background-color: #e5e7eb;
            border-radius: 2px;
            overflow: hidden;
            margin: 1rem 0;
            display: none;
        }

        .progress-fill {
            height: 100%;
            background-color: var(--primary);
            width: 0%;
            transition: width 0.3s;
        }

        .status {
            text-align: center;
            font-size: 0.875rem;
            color: #6b7280;
            margin-top: 0.5rem;
        }

        .toast {
            position: fixed;
            bottom: 2rem;
            right: 2rem;
            background: #059669;
            color: white;
            padding: 1rem 2rem;
            border-radius: 0.5rem;
            box-shadow: 0 4px 6px -1px rgb(0 0 0 / 0.1);
            display: none;
            animation: slideIn 0.3s ease-out;
        }

        @keyframes slideIn {
            from { transform: translateX(100%); opacity: 0; }
            to { transform: translateX(0); opacity: 1; }
        }

        .file-info {
            display: flex;
            align-items: center;
            gap: 1rem;
            margin-top: 1rem;
            padding: 0.75rem;
            background: #f8fafc;
            border-radius: 0.5rem;
            border: 1px solid var(--border);
        }

        .file-info i {
            font-size: 1.5rem;
            color: var(--primary);
        }

        .conversion-status {
            margin-top: 0.5rem;
            font-size: 0.875rem;
            color: #059669;
        }

        .error-message {
            color: #dc2626;
            font-size: 0.875rem;
            margin-top: 0.5rem;
        }

        .usage-info {
            text-align: center;
            margin-top: 1rem;
            font-size: 0.875rem;
            color: #6b7280;
        }

        .error {
    border-color: #dc2626 !important;
}

.input-group.error label {
    color: #dc2626;
}

.error-message {
    color: #dc2626;
    font-size: 0.875rem;
    margin-top: 0.5rem;
    animation: fadeIn 0.3s ease-in;
}

@keyframes fadeIn {
    from { opacity: 0; }
    to { opacity: 1; }
}

        .conversion-progress-bar {
    height: 4px;
    background-color: #e5e7eb;
    border-radius: 2px;
    overflow: hidden;
    margin: 1rem 0;
}

.conversion-progress-bar .progress-fill {
    height: 100%;
    background-color: var(--primary);
    width: 0%;
    transition: width 0.3s ease;
}

.conversion-status {
    display: flex;
    align-items: center;
    justify-content: center;
    gap: 0.5rem;
    margin-top: 0.5rem;
    font-size: 0.875rem;
    color: var(--primary);
}
        
    </style>
</head>
<body>
    <div class="container">
        <div class="card">
            <h1>Video Transcriber</h1>

            <!-- API Configuration -->
            <div class="config-form">
                <div class="input-group">
                    <label for="apiKey">Key</label>
                    <input type="password" id="apiKey" placeholder="Enter your key">
                </div>
                <div class="input-group">
                    <label for="language">Recognition Language</label>
                    <select id="language">
                        <option value="en-US">English</option>
                        <option value="hi-IN">Hindi</option>
                        <option value="fr-FR">French</option>
                        <option value="de-DE">German</option>
                        <option value="it-IT">Italian</option>
                        <option value="ja-JP">Japanese</option>
                    </select>
                </div>
            </div>

            <!-- Upload Zone -->
            <div class="upload-zone" id="dropZone">
                <input type="file" id="audioFile" accept="audio/*,video/mp4" style="display: none">
                <i class="fas fa-cloud-upload-alt" style="font-size: 2rem; color: var(--primary); margin-bottom: 1rem;"></i>
                <p>Drag and drop your audio or video file here or</p>
                <button class="button button-secondary" onclick="document.getElementById('audioFile').click()">
                    <i class="fas fa-file-audio"></i>
                    Choose File
                </button>
                <div class="status" id="fileStatus"></div>
                <div id="conversionStatus" class="conversion-status"></div>
                <div id="errorMessage" class="error-message"></div>
            </div>

            <!-- Actions -->
            <div class="actions">
                <button class="button" id="startTranscription" disabled>
                    <i class="fas fa-play"></i>
                    Start Transcription
                </button>
                <button class="button button-secondary" id="checkUsage">
                    <i class="fas fa-chart-bar"></i>
                    Check Usage
                </button>
            </div>

            <!-- Progress Bar -->

            <!-- Add this after the existing progress bar -->
<div class="conversion-progress-bar" id="conversionProgressBar" style="display: none;">
    <div class="progress-fill" id="conversionProgressFill"></div>
</div>
            <div class="progress-bar" id="progressBar">
                <div class="progress-fill" id="progressBarFill"></div>
            </div>

            <!-- Output -->
            <div class="output-container">
                <div class="output" id="transcriptionOutput"></div>
                <button class="copy-button" id="copyButton" title="Copy to clipboard">
                    <i class="fas fa-copy"></i>
                </button>
                <button class="button button-secondary" id="downloadText" disabled>
                    <i class="fas fa-download"></i>
                    save
                </button>
            </div>

            <!-- Usage Info -->
            <div class="usage-info" id="usageInfo"></div>
        </div>
    </div>

    <!-- Toast Notification -->
    <div class="toast" id="toast">Copied to clipboard!</div>

    <script>
        let audioFile = null;
        let transcriptionText = "";
        let isConverting = false;
        let audioContext = null;

        // Azure region (predefined)
        const AZURE_REGION = 'centralindia';

        function validateApiKey(key) {
    // Azure API keys are 32 characters long
    if (!/^[0-9a-f]{32}$/i.test(key)) {
        throw new Error('Invalid API key format');
    }
    return true;
}

elements.apiKey.addEventListener('change', () => {
    try {
        if (elements.apiKey.value) {
            validateApiKey(elements.apiKey.value);
            elements.apiKey.classList.remove('error');
            elements.errorMessage.textContent = '';
        }
    } catch (error) {
        elements.apiKey.classList.add('error');
        elements.errorMessage.textContent = error.message;
    }
});

        document.addEventListener('DOMContentLoaded', () => {
    // Check for required APIs
    if (!window.File || !window.FileReader || !window.FileList || !window.Blob) {
        elements.errorMessage.textContent = 'File APIs not supported in this browser';
        return;
    }

    if (!window.AudioContext && !window.webkitAudioContext) {
        elements.errorMessage.textContent = 'Web Audio API not supported in this browser';
        return;
    }

    if (!window.MediaRecorder) {
        elements.errorMessage.textContent = 'MediaRecorder API not supported in this browser';
        return;
    }

    // Check if Speech SDK loaded
    if (typeof SpeechSDK === 'undefined') {
        elements.errorMessage.textContent = 'Speech SDK failed to load';
        return;
    }
});

        // DOM Elements
        const elements = {
            conversionProgressBar: document.getElementById('conversionProgressBar'),
    conversionProgressFill: document.getElementById('conversionProgressFill'),
            apiKey: document.getElementById('apiKey'),
            language: document.getElementById('language'),
            dropZone: document.getElementById('dropZone'),
            fileInput: document.getElementById('audioFile'),
            fileStatus: document.getElementById('fileStatus'),
            startButton: document.getElementById('startTranscription'),
            downloadButton: document.getElementById('downloadText'),
            checkUsageButton: document.getElementById('checkUsage'),
            outputDiv: document.getElementById('transcriptionOutput'),
            progressBar: document.getElementById('progressBar'),
            progressBarFill: document.getElementById('progressBarFill'),
            copyButton: document.getElementById('copyButton'),
            toast: document.getElementById('toast'),
            conversionStatus: document.getElementById('conversionStatus'),
            errorMessage: document.getElementById('errorMessage'),
            usageInfo: document.getElementById('usageInfo')
        };

        // File Handling
        async function handleFile(file) {
            elements.errorMessage.textContent = '';
            elements.conversionStatus.textContent = '';
            
            if (file.type.startsWith('audio/')) {
                audioFile = file;
                elements.fileStatus.textContent = `Selected audio: ${file.name}`;
                elements.startButton.disabled = !validateConfig();
            } else if (file.type === 'video/mp4') {
                elements.fileStatus.textContent = `Selected video: ${file.name}`;
                elements.startButton.disabled = true;
                isConverting = true;
                await extractAudioFromVideo(file);
                isConverting = false;
            } else {
                elements.fileStatus.textContent = 'Please select a valid audio or video file';
                elements.startButton.disabled = true;
            }
        }

        // Function to convert MP4 to AudioBuffer
        async function extractAudioFromVideo(videoFile) {
    try {
        elements.conversionStatus.textContent = 'Converting video to audio...';
        elements.conversionProgressBar.style.display = 'block';
        elements.conversionProgressFill.style.width = '0%';
        
        const video = document.createElement('video');
        video.src = URL.createObjectURL(videoFile);
        video.muted = true;

        // Wait for metadata to load
        await new Promise((resolve, reject) => {
            video.onloadedmetadata = resolve;
            video.onerror = () => reject(new Error('Failed to load video'));
            video.load();
        });

        // Get video duration
        const duration = video.duration;
        
        // Initialize audio context
        audioContext = new (window.AudioContext || window.webkitAudioContext)();
        const destination = audioContext.createMediaStreamDestination();
        const source = audioContext.createMediaElementSource(video);
        source.connect(destination);

        const mediaRecorder = new MediaRecorder(destination.stream, {
            mimeType: 'audio/webm;codecs=opus',
            audioBitsPerSecond: 128000
        });

        const audioChunks = [];
        
        mediaRecorder.ondataavailable = (event) => {
            if (event.data.size > 0) {
                audioChunks.push(event.data);
            }
        };

        // Update progress based on video current time
        video.ontimeupdate = () => {
            const progress = (video.currentTime / duration) * 100;
            elements.conversionProgressFill.style.width = `${progress}%`;
            elements.conversionStatus.textContent = 
                `Converting video to audio... ${Math.round(progress)}%`;
        };

        return new Promise((resolve, reject) => {
            mediaRecorder.onstop = async () => {
                try {
                    // Set progress to 100% for final processing
                    elements.conversionProgressFill.style.width = '100%';
                    elements.conversionStatus.textContent = 'Processing audio...';

                    const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                    // Convert to wav format
                    const arrayBuffer = await audioBlob.arrayBuffer();
                    audioFile = new File([arrayBuffer], 'converted_audio.wav', { 
                        type: 'audio/wav' 
                    });

                    elements.conversionStatus.textContent = 'Conversion completed successfully!';
                    elements.startButton.disabled = !validateConfig();
                    
                    // Hide progress bar after completion
                    setTimeout(() => {
                        elements.conversionProgressBar.style.display = 'none';
                    }, 1000);

                    URL.revokeObjectURL(video.src);
                    resolve();
                } catch (error) {
                    reject(error);
                }
            };

            mediaRecorder.onerror = (error) => {
                elements.conversionProgressBar.style.display = 'none';
                reject(new Error('MediaRecorder error: ' + error.message));
            };

            // Start recording and playing
            mediaRecorder.start(100); // Collect data every 100ms
            video.play();

            // Stop when video ends
            video.onended = () => {
                mediaRecorder.stop();
                video.remove();
            };
        });
        
    } catch (error) {
        elements.conversionProgressBar.style.display = 'none';
        elements.errorMessage.textContent = 'Error converting video: ' + error.message;
        console.error('Video conversion error:', error);
        throw error;
    }
}

        function resetConversionProgress() {
    elements.conversionProgressBar.style.display = 'none';
    elements.conversionProgressFill.style.width = '0%';
    elements.conversionStatus.textContent = '';
}

// Add to your handleFile function
async function handleFile(file) {
    elements.errorMessage.textContent = '';
    elements.conversionStatus.textContent = '';
    resetConversionProgress();
    
    try {
        // ... rest of the code ...
    } catch (error) {
        resetConversionProgress();
        elements.errorMessage.textContent = error.message;
        elements.fileStatus.textContent = 'Error processing file';
        console.error('File handling error:', error);
    }
}

        function validateFile(file) {
    const MAX_FILE_SIZE = 100 * 1024 * 1024; // 100MB
    
    if (file.size > MAX_FILE_SIZE) {
        throw new Error('File size exceeds 100MB limit');
    }

    const allowedTypes = [
        'audio/wav',
        'audio/mp3',
        'audio/mpeg',
        'audio/webm',
        'video/mp4'
    ];

    if (!allowedTypes.includes(file.type)) {
        throw new Error('Unsupported file type. Please use WAV, MP3, or MP4 files.');
    }

    return true;
        }


        async function handleFile(file) {
    elements.errorMessage.textContent = '';
    elements.conversionStatus.textContent = '';
    elements.startButton.disabled = true;
    
    try {
        validateFile(file);
        
        if (file.type.startsWith('audio/')) {
            audioFile = file;
            elements.fileStatus.textContent = `Selected audio: ${file.name}`;
            elements.startButton.disabled = !validateConfig();
        } else if (file.type === 'video/mp4') {
            elements.fileStatus.textContent = `Selected video: ${file.name} (Converting...)`;
            isConverting = true;
            await extractAudioFromVideo(file);
            isConverting = false;
        }
    } catch (error) {
        elements.errorMessage.textContent = error.message;
        elements.fileStatus.textContent = 'Error processing file';
        console.error('File handling error:', error);
    }
}

        function cleanup() {
    if (audioFile && audioFile instanceof File) {
        URL.revokeObjectURL(URL.createObjectURL(audioFile));
    }
    if (audioContext) {
        audioContext.close();
    }
}

// Add to window unload event
window.addEventListener('unload', cleanup);


        let totalTranscriptionTime = 0;
let transcriptionStartTime = 0;

function updateProgress(percentage) {
    elements.progressBarFill.style.width = `${percentage}%`;
    if (percentage === 100) {
        const duration = (Date.now() - transcriptionStartTime) / 1000;
        totalTranscriptionTime += duration;
    }
}

        

        
        // Drag and Drop
        elements.dropZone.addEventListener('dragover', (e) => {
            e.preventDefault();
            elements.dropZone.classList.add('drag-over');
        });

        elements.dropZone.addEventListener('dragleave', () => {
            elements.dropZone.classList.remove('drag-over');
        });

        elements.dropZone.addEventListener('drop', (e) => {
            e.preventDefault();
            elements.dropZone.classList.remove('drag-over');
            handleFile(e.dataTransfer.files[0]);
        });

        elements.fileInput.addEventListener('change', (e) => {
            handleFile(e.target.files[0]);
        });

        // Config Validation
        function validateConfig() {
            return elements.apiKey.value && 
                   elements.language.value && 
                   audioFile &&
                   !isConverting;
        }

        // Input Event Listeners
        [elements.apiKey, elements.language].forEach(input => {
            input.addEventListener('input', () => {
                elements.startButton.disabled = !validateConfig();
            });
        });

        // Transcription
        elements.startButton.addEventListener('click', async () => {
    if (!validateConfig()) return;

    // Reset UI
    elements.outputDiv.textContent = '';
    elements.progressBar.style.display = 'block';
    elements.startButton.disabled = true;
    elements.downloadButton.disabled = true;
    transcriptionText = '';

    try {
        const speechConfig = SpeechSDK.SpeechConfig.fromSubscription(
            elements.apiKey.value,
            AZURE_REGION
        );
        speechConfig.speechRecognitionLanguage = elements.language.value;

        // Create audio format for recognizer
        const audioFormat = SpeechSDK.AudioStreamFormat.getWaveFormatPCM(16000, 16, 1); // 16kHz, 16-bit, mono
        
        let audioConfig;
        try {
            const arrayBuffer = await audioFile.arrayBuffer();
            const audioData = new Uint8Array(arrayBuffer);
            const pushStream = SpeechSDK.AudioInputStream.createPushStream(audioFormat);
            
            // Push audio data to stream
            pushStream.write(audioData);
            pushStream.close();
            
            audioConfig = SpeechSDK.AudioConfig.fromStreamInput(pushStream);
        } catch (error) {
            throw new Error('Error processing audio file: ' + error.message);
        }

        const recognizer = new SpeechSDK.SpeechRecognizer(speechConfig, audioConfig);

        // Add recognition started event
        recognizer.recognizing = (s, e) => {
            console.log(`RECOGNIZING: Text=${e.result.text}`);
            // Update progress bar for feedback
            elements.progressBarFill.style.width = '50%';
        };

        // Recognition completed event
        recognizer.recognized = (s, e) => {
            if (e.result.reason === SpeechSDK.ResultReason.RecognizedSpeech) {
                transcriptionText += e.result.text + " ";
                elements.outputDiv.textContent = transcriptionText;
                elements.progressBarFill.style.width = '100%';
            } else if (e.result.reason === SpeechSDK.ResultReason.NoMatch) {
                console.log(`NOMATCH: Speech could not be recognized.`);
            }
        };

        // Start continuous recognition
        recognizer.startContinuousRecognitionAsync(
            () => {
                console.log('Recognition started');
            },
            (error) => {
                console.error('Error during recognition:', error);
                elements.errorMessage.textContent = 'Transcription error: ' + error;
                recognizer.close();
            }
        );

        // Stop recognition after file duration
        setTimeout(() => {
            recognizer.stopContinuousRecognitionAsync(
                () => {
                    console.log('Recognition stopped');
                    elements.downloadButton.disabled = false;
                    elements.startButton.disabled = false;
                    recognizer.close();
                },
                (error) => {
                    console.error('Error stopping recognition:', error);
                    elements.errorMessage.textContent = 'Error stopping transcription';
                    recognizer.close();
                }
            );
        }, 30000); // Adjust timeout based on your needs

    } catch (error) {
        console.error('Error:', error);
        elements.errorMessage.textContent = 'Error: ' + error.message;
        elements.startButton.disabled = false;
    }
});
        // Download Function
        elements.downloadButton.addEventListener('click', () => {
            if (!transcriptionText) return;

            const blob = new Blob([transcriptionText], { type: 'text/plain' });
            const url = window.URL.createObjectURL(blob);
            const a = document.createElement('a');
            a.href = url;
            a.download = 'transcription.txt';
            document.body.appendChild(a);
            a.click();
            window.URL.revokeObjectURL(url);
            document.body.removeChild(a);
        });

        // Copy Function
        elements.copyButton.addEventListener('click', () => {
            if (!transcriptionText) return;

            navigator.clipboard.writeText(transcriptionText).then(() => {
                elements.toast.style.display = 'block';
                setTimeout(() => {
                    elements.toast.style.display = 'none';
                }, 3000);
            });
        });

        // Check Usage Function
        elements.checkUsageButton.addEventListener('click', async () => {
    if (!elements.apiKey.value) {
        elements.usageInfo.textContent = 'Please enter your API key to check usage.';
        return;
    }

    try {
        // First, make sure we're using the correct endpoint
        const endpoint = `https://${AZURE_REGION}.api.cognitive.microsoft.com/speech/speaker/verification/v2.0/text-independent/profiles`;
        
        const response = await fetch(endpoint, {
            method: 'GET',
            headers: {
                'Ocp-Apim-Subscription-Key': elements.apiKey.value,
                'Content-Type': 'application/json'
            }
        });

        if (!response.ok) {
            throw new Error(`HTTP error! status: ${response.status}`);
        }

        const data = await response.json();
        
        // Display usage information
        elements.usageInfo.innerHTML = `
            <div>
                <p>Subscription Status: Active</p>
                <p>API Calls Today: ${data.length || 0}</p>
            </div>
        `;
    } catch (error) {
        console.error('Error checking usage:', error);
        elements.usageInfo.textContent = 'Error checking usage. Please verify your API key and try again.';
    }
});
        // Cleanup function for audio context
        window.addEventListener('beforeunload', () => {
            if (audioContext) {
                audioContext.close();
            }
        });
    </script>
</body>
</html>
